{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083cc29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [v19 TEST] A processar test set...\n",
      "Preparar previs√£o para o ano 11 (usando T-1 = 10)\n",
      "\n",
      "‚úÖ TEST v19 criado com sucesso ‚Üí a/teams_test_v19.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18847/230067960.py:122: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  roster_test[\"player_rating_prev\"].fillna(mean_rating_prev, inplace=True)\n",
      "/tmp/ipykernel_18847/230067960.py:123: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  roster_test[\"minutes_prev\"].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_18847/230067960.py:124: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  roster_test[\"num_awards\"].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_18847/230067960.py:138: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(build_team_features)\n",
      "/tmp/ipykernel_18847/230067960.py:155: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  team_stats[\"elite_ratio_prev\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 01_b_processing_v19_test.py\n",
    "# ===============================================================\n",
    "# Constr√≥i dataset TEST v19 (para previs√£o final)\n",
    "# Usa APENAS dados permitidos pelo professor (coaches, players_teams, teams)\n",
    "# NUNCA usa rank, vit√≥rias, pontos ou estat√≠sticas do ano atual.\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\">>> [v19 TEST] A processar test set...\")\n",
    "\n",
    "# ===============================================================\n",
    "# 1Ô∏è‚É£ Ler dados DO TEST SET (dados do professor)\n",
    "# ===============================================================\n",
    "players_teams_test = pd.read_csv(\"Season_11/players_teams.csv\")\n",
    "teams_test = pd.read_csv(\"Season_11/teams.csv\")\n",
    "coaches_test = pd.read_csv(\"Season_11/coaches.csv\")   # usado s√≥ se precisares mais tarde\n",
    "\n",
    "# ===============================================================\n",
    "# 2Ô∏è‚É£ Ler dados hist√≥ricos (para obter T‚àí1)\n",
    "# ===============================================================\n",
    "players_teams_hist = pd.read_csv(\"data/players_teams.csv\")\n",
    "teams_hist = pd.read_csv(\"data/teams.csv\")\n",
    "awards_hist = pd.read_csv(\"data/awards_players.csv\")\n",
    "\n",
    "# Garantir ano num√©rico\n",
    "for df in (players_teams_hist, players_teams_test, teams_hist, teams_test, awards_hist):\n",
    "    if \"year\" in df.columns:\n",
    "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        df.dropna(subset=[\"year\"], inplace=True)\n",
    "        df[\"year\"] = df[\"year\"].astype(int)\n",
    "\n",
    "test_year = teams_test[\"year\"].iloc[0]\n",
    "prev_year = test_year - 1\n",
    "\n",
    "print(f\"Preparar previs√£o para o ano {test_year} (usando T-1 = {prev_year})\")\n",
    "\n",
    "# ===============================================================\n",
    "# 3Ô∏è‚É£ Calcular player_rating_prev usando hist√≥rico\n",
    "# ===============================================================\n",
    "cols_needed = [\"playerID\",\"year\",\"points\",\"rebounds\",\"assists\",\"steals\",\"blocks\",\n",
    "               \"turnovers\",\"minutes\",\"threeMade\",\"threeAttempted\",\"fgMade\",\n",
    "               \"fgAttempted\",\"PF\",\"GP\"]\n",
    "for c in cols_needed:\n",
    "    if c not in players_teams_hist.columns:\n",
    "        players_teams_hist[c] = 0\n",
    "\n",
    "agg = (\n",
    "    players_teams_hist.groupby([\"playerID\", \"year\"], as_index=False)\n",
    "    .agg(\n",
    "        minutes=(\"minutes\",\"sum\"),\n",
    "        points=(\"points\",\"sum\"),\n",
    "        rebounds=(\"rebounds\",\"sum\"),\n",
    "        assists=(\"assists\",\"sum\"),\n",
    "        steals=(\"steals\",\"sum\"),\n",
    "        blocks=(\"blocks\",\"sum\"),\n",
    "        turnovers=(\"turnovers\",\"sum\"),\n",
    "        threeMade=(\"threeMade\",\"sum\"),\n",
    "        threeAttempted=(\"threeAttempted\",\"sum\"),\n",
    "        fgMade=(\"fgMade\",\"sum\"),\n",
    "        fgAttempted=(\"fgAttempted\",\"sum\"),\n",
    "        PF=(\"PF\",\"sum\"),\n",
    "        GP=(\"GP\",\"sum\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# rating\n",
    "agg[\"player_rating\"] = (\n",
    "      agg[\"points\"]\n",
    "    + agg[\"rebounds\"] * 1.2\n",
    "    + agg[\"assists\"] * 1.5\n",
    "    + agg[\"steals\"] * 3\n",
    "    + agg[\"blocks\"] * 3\n",
    "    - agg[\"turnovers\"] * 2\n",
    "    - agg[\"PF\"] * 0.5\n",
    ") / (agg[\"minutes\"] / 36 + 1)\n",
    "\n",
    "# filtrar players com minutos\n",
    "agg = agg[agg[\"minutes\"] > 50]\n",
    "\n",
    "# criar T‚àí1 map\n",
    "prev_map = agg[agg[\"year\"] == prev_year].copy()\n",
    "prev_map = prev_map.rename(columns={\"player_rating\": \"player_rating_prev\"})\n",
    "prev_map = prev_map[[\"playerID\", \"player_rating_prev\", \"minutes\"]]\n",
    "prev_map = prev_map.rename(columns={\"minutes\": \"minutes_prev\"})\n",
    "\n",
    "# ===============================================================\n",
    "# 4Ô∏è‚É£ Integrar pr√©mios T‚àí1\n",
    "# ===============================================================\n",
    "awards_prev = awards_hist[awards_hist[\"year\"] == prev_year]\n",
    "awards_prev = awards_prev[awards_prev[\"award\"] != \"Coach of the Year\"]\n",
    "\n",
    "award_weights = {\n",
    "    \"Most Valuable Player\": 5,\n",
    "    \"WNBA Finals Most Valuable Player\": 4,\n",
    "    \"Defensive Player of the Year\": 3,\n",
    "    \"Rookie of the Year\": 2,\n",
    "}\n",
    "\n",
    "awards_prev[\"award_weight\"] = awards_prev[\"award\"].map(award_weights).fillna(1.0)\n",
    "\n",
    "award_counts = (\n",
    "    awards_prev.groupby(\"playerID\")[\"award_weight\"]\n",
    "    .sum().reset_index()\n",
    "    .rename(columns={\"award_weight\":\"num_awards\"})\n",
    ")\n",
    "\n",
    "prev_map = prev_map.merge(award_counts, on=\"playerID\", how=\"left\")\n",
    "prev_map[\"num_awards\"] = prev_map[\"num_awards\"].fillna(0)\n",
    "prev_map[\"player_rating_prev\"] *= (1 + 0.3 * prev_map[\"num_awards\"])\n",
    "\n",
    "# ===============================================================\n",
    "# 5Ô∏è‚É£ Roster T‚àí1 baseado no test/players_teams\n",
    "# ===============================================================\n",
    "roster_test = players_teams_test[[\"playerID\",\"tmID\",\"year\"]].drop_duplicates()\n",
    "roster_test = roster_test.merge(prev_map, on=\"playerID\", how=\"left\")\n",
    "\n",
    "mean_rating_prev = prev_map[\"player_rating_prev\"].mean()\n",
    "roster_test[\"player_rating_prev\"].fillna(mean_rating_prev, inplace=True)\n",
    "roster_test[\"minutes_prev\"].fillna(0, inplace=True)\n",
    "roster_test[\"num_awards\"].fillna(0, inplace=True)\n",
    "\n",
    "# ===============================================================\n",
    "# 6Ô∏è‚É£ Construir features por equipa (somente as 4)\n",
    "# ===============================================================\n",
    "def build_team_features(df):\n",
    "    w = df[\"minutes_prev\"].replace(0, np.nan).fillna(1.0)\n",
    "    return pd.Series({\n",
    "        \"avg_player_rating\": np.average(df[\"player_rating_prev\"], weights=w),\n",
    "        \"team_total_awards\": df[\"num_awards\"].sum(),\n",
    "    })\n",
    "\n",
    "team_stats = (\n",
    "    roster_test.groupby([\"tmID\",\"year\"], as_index=False)\n",
    "    .apply(build_team_features)\n",
    "    .reset_index()\n",
    "    .drop(columns=[\"level_2\"], errors=\"ignore\")\n",
    ")\n",
    "\n",
    "# ELITE RATIO T‚àí1\n",
    "elite_cutoff = prev_map[\"player_rating_prev\"].quantile(0.90)\n",
    "prev_map[\"is_elite\"] = (prev_map[\"player_rating_prev\"] >= elite_cutoff).astype(int)\n",
    "\n",
    "elite_ratio = (\n",
    "    roster_test.merge(prev_map[[\"playerID\",\"is_elite\"]], on=\"playerID\", how=\"left\")\n",
    "    .groupby([\"tmID\",\"year\"], as_index=False)[\"is_elite\"]\n",
    "    .mean()\n",
    "    .rename(columns={\"is_elite\":\"elite_ratio_prev\"})\n",
    ")\n",
    "\n",
    "team_stats = team_stats.merge(elite_ratio, on=[\"tmID\",\"year\"], how=\"left\")\n",
    "team_stats[\"elite_ratio_prev\"].fillna(0, inplace=True)\n",
    "\n",
    "# ===============================================================\n",
    "# 7Ô∏è‚É£ margin_prev usando hist√≥rico (teams_hist)\n",
    "# ===============================================================\n",
    "teams_hist = teams_hist.sort_values([\"tmID\", \"year\"])\n",
    "\n",
    "teams_hist[\"o_pts_prev\"] = teams_hist.groupby(\"tmID\")[\"o_pts\"].shift(1)\n",
    "teams_hist[\"d_pts_prev\"] = teams_hist.groupby(\"tmID\")[\"d_pts\"].shift(1)\n",
    "teams_hist[\"GP_prev\"] = teams_hist.groupby(\"tmID\")[\"GP\"].shift(1)\n",
    "\n",
    "teams_hist[\"margin_prev\"] = (\n",
    "    teams_hist[\"o_pts_prev\"] - teams_hist[\"d_pts_prev\"]\n",
    ") / teams_hist[\"GP_prev\"].replace(0, np.nan)\n",
    "\n",
    "teams_prev_year = teams_hist[teams_hist[\"year\"] == prev_year][[\"tmID\",\"margin_prev\"]]\n",
    "\n",
    "# ===============================================================\n",
    "# 8Ô∏è‚É£ Merge final\n",
    "# ===============================================================\n",
    "test_ready = teams_test.merge(team_stats, on=[\"tmID\",\"year\"], how=\"left\")\n",
    "test_ready = test_ready.merge(teams_prev_year, on=\"tmID\", how=\"left\")\n",
    "\n",
    "test_ready.fillna(0, inplace=True)\n",
    "\n",
    "# ===============================================================\n",
    "# 9Ô∏è‚É£ Guardar TEST FINAL\n",
    "# ===============================================================\n",
    "final_cols = [\n",
    "    \"tmID\",\"year\",\"confID\",\n",
    "    \"margin_prev\",\"avg_player_rating\",\"team_total_awards\",\"elite_ratio_prev\"\n",
    "]\n",
    "\n",
    "final_test = test_ready[final_cols].copy()\n",
    "\n",
    "os.makedirs(\"a\", exist_ok=True)\n",
    "out_path = \"a/teams_test_v19.csv\"\n",
    "final_test.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ TEST v19 criado com sucesso ‚Üí {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a00cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [v19 TEST] Prever ranking do test set...\n",
      "\n",
      "‚úî Modelo carregado.\n",
      "‚úî Test set carregado.\n",
      "  tmID  year confID  margin_prev  avg_player_rating  team_total_awards  \\\n",
      "0  ATL    11     EA   -10.147059          26.837347                2.0   \n",
      "1  CHI    11     EA    -1.117647          21.072279                0.0   \n",
      "2  CON    11     EA     4.382353          22.162138                1.0   \n",
      "3  IND    11     EA     0.470588          30.870707                3.0   \n",
      "4  LAS    11     WE     2.205882          22.974650                0.0   \n",
      "\n",
      "   elite_ratio_prev  \n",
      "0             0.300  \n",
      "1             0.000  \n",
      "2             0.000  \n",
      "3             0.100  \n",
      "4             0.125  \n",
      "\n",
      "‚úî Previs√µes criadas com sucesso!\n",
      "Guardado em: a/predictions_test_v19.csv\n",
      "\n",
      "Preview:\n",
      "   tmID confID  year  rank_pred\n",
      "3   IND     EA    11        1.0\n",
      "2   CON     EA    11        2.0\n",
      "6   NYL     EA    11        3.0\n",
      "0   ATL     EA    11        4.0\n",
      "11  WAS     EA    11        5.0\n",
      "1   CHI     EA    11        6.0\n",
      "7   PHO     WE    11        1.0\n",
      "8   SAS     WE    11        2.0\n",
      "5   MIN     WE    11        3.0\n",
      "9   SEA     WE    11        4.0\n",
      "4   LAS     WE    11        5.0\n",
      "10  TUL     WE    11        6.0\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 04_a_predict_v19.py  (VERS√ÉO CORRETA)\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"\\n>>> [v19 TEST] Prever ranking do test set...\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Carregar modelo treinado\n",
    "# ---------------------------------------------------------------\n",
    "MODEL_PATH = \"a/model_v19.pkl\"\n",
    "with open(MODEL_PATH, \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(\"‚úî Modelo carregado.\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Carregar test set j√° processado (feito no script 02)\n",
    "# ---------------------------------------------------------------\n",
    "TEST_PATH = \"a/teams_test_v19.csv\"\n",
    "\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    raise FileNotFoundError(\"‚ùå ERRO: 'teams_test_v19.csv' n√£o existe.\\nCorre o script 02 primeiro.\")\n",
    "\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"‚úî Test set carregado.\")\n",
    "print(test.head())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Features\n",
    "# ---------------------------------------------------------------\n",
    "X_COLS = [\"margin_prev\", \"avg_player_rating\", \"team_total_awards\", \"elite_ratio_prev\"]\n",
    "X = test[X_COLS]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Previs√£o\n",
    "# ---------------------------------------------------------------\n",
    "test[\"pred_raw\"] = model.predict(X)\n",
    "\n",
    "# Ranking por confer√™ncia\n",
    "test[\"rank_pred\"] = test.groupby(\"confID\")[\"pred_raw\"].rank(ascending=True, method=\"min\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5) Guardar\n",
    "# ---------------------------------------------------------------\n",
    "OUTPUT = test[[\"tmID\", \"confID\", \"year\", \"rank_pred\"]].sort_values([\"confID\", \"rank_pred\"])\n",
    "\n",
    "OUTPUT_PATH = \"a/predictions_test_v19.csv\"\n",
    "OUTPUT.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"\\n‚úî Previs√µes criadas com sucesso!\")\n",
    "print(\"Guardado em:\", OUTPUT_PATH)\n",
    "print(\"\\nPreview:\")\n",
    "print(OUTPUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2e1439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [v19 TEST] Prever ranking do test set com modelos por confer√™ncia...\n",
      "\n",
      "‚úî Modelos carregados (EA = RF | WE = LR).\n",
      "‚úî Test set carregado.\n",
      "  tmID  year confID  margin_prev  avg_player_rating  team_total_awards  \\\n",
      "0  ATL    11     EA   -10.147059          26.837347                2.0   \n",
      "1  CHI    11     EA    -1.117647          21.072279                0.0   \n",
      "2  CON    11     EA     4.382353          22.162138                1.0   \n",
      "3  IND    11     EA     0.470588          30.870707                3.0   \n",
      "4  LAS    11     WE     2.205882          22.974650                0.0   \n",
      "\n",
      "   elite_ratio_prev  \n",
      "0             0.300  \n",
      "1             0.000  \n",
      "2             0.000  \n",
      "3             0.100  \n",
      "4             0.125  \n",
      "\n",
      "‚úî Previs√µes criadas com sucesso!\n",
      "Guardado em: a/predictions_test_v19_by_conf.csv\n",
      "\n",
      "Preview:\n",
      "   tmID confID  year  rank_pred\n",
      "0   ATL     EA    11        1.0\n",
      "11  WAS     EA    11        2.0\n",
      "3   IND     EA    11        3.0\n",
      "2   CON     EA    11        4.0\n",
      "1   CHI     EA    11        5.0\n",
      "6   NYL     EA    11        6.0\n",
      "7   PHO     WE    11        1.0\n",
      "8   SAS     WE    11        2.0\n",
      "5   MIN     WE    11        3.0\n",
      "9   SEA     WE    11        4.0\n",
      "4   LAS     WE    11        5.0\n",
      "10  TUL     WE    11        6.0\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# ü§ñ 04_a_predict_v19_by_conf.py\n",
    "# ===============================================================\n",
    "# Usa os modelos treinados por confer√™ncia:\n",
    "# - Western Conference (WE): Linear Regression\n",
    "# - Eastern Conference (EA): Random Forest\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"\\n>>> [v19 TEST] Prever ranking do test set com modelos por confer√™ncia...\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1) Carregar modelos treinados\n",
    "# ---------------------------------------------------------------\n",
    "MODEL_EA_PATH = \"a/model_EA_v19.pkl\"\n",
    "MODEL_WE_PATH = \"a/model_WE_v19.pkl\"\n",
    "\n",
    "with open(MODEL_EA_PATH, \"rb\") as f:\n",
    "    model_EA = pickle.load(f)\n",
    "\n",
    "with open(MODEL_WE_PATH, \"rb\") as f:\n",
    "    model_WE = pickle.load(f)\n",
    "\n",
    "print(\"‚úî Modelos carregados (EA = RF | WE = LR).\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2) Carregar test set j√° processado\n",
    "# ---------------------------------------------------------------\n",
    "TEST_PATH = \"a/teams_test_v19.csv\"\n",
    "\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    raise FileNotFoundError(\"‚ùå ERRO: 'teams_test_v19.csv' n√£o existe.\\nCorre o script 02 primeiro.\")\n",
    "\n",
    "test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "print(\"‚úî Test set carregado.\")\n",
    "print(test.head())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3) Features\n",
    "# ---------------------------------------------------------------\n",
    "X_COLS = [\"margin_prev\", \"avg_player_rating\", \"team_total_awards\", \"elite_ratio_prev\"]\n",
    "\n",
    "# Criar coluna para previs√µes vazias\n",
    "test[\"pred_raw\"] = np.nan\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4) Previs√£o por confer√™ncia\n",
    "# ---------------------------------------------------------------\n",
    "for conf, model in [(\"EA\", model_EA), (\"WE\", model_WE)]:\n",
    "    subset = test[\"confID\"] == conf\n",
    "    X = test.loc[subset, X_COLS]\n",
    "    test.loc[subset, \"pred_raw\"] = model.predict(X)\n",
    "\n",
    "# Ranking final por confer√™ncia\n",
    "test[\"rank_pred\"] = test.groupby(\"confID\")[\"pred_raw\"].rank(ascending=True, method=\"min\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5) Guardar resultados\n",
    "# ---------------------------------------------------------------\n",
    "OUTPUT = test[[\"tmID\", \"confID\", \"year\", \"rank_pred\"]].sort_values([\"confID\", \"rank_pred\"])\n",
    "\n",
    "OUTPUT_PATH = \"a/predictions_test_v19_by_conf.csv\"\n",
    "OUTPUT.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"\\n‚úî Previs√µes criadas com sucesso!\")\n",
    "print(\"Guardado em:\", OUTPUT_PATH)\n",
    "print(\"\\nPreview:\")\n",
    "print(OUTPUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv - ac)",
   "language": "python",
   "name": "ac-data-mining-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
